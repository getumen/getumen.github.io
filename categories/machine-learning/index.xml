<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on 雑記</title>
    <link>https://getumen.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on 雑記</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 02 Jan 2019 21:34:59 +0900</lastBuildDate>
    
	<atom:link href="https://getumen.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems １章 (2)</title>
      <link>https://getumen.github.io/2019/01/02/regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems-%EF%BC%91%E7%AB%A0-2/</link>
      <pubDate>Wed, 02 Jan 2019 21:34:59 +0900</pubDate>
      
      <guid>https://getumen.github.io/2019/01/02/regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems-%EF%BC%91%E7%AB%A0-2/</guid>
      <description>&lt;h1 id=&#34;導入&#34;&gt;導入&lt;/h1&gt;

&lt;h2 id=&#34;確率的バンディット問題の設定とは&#34;&gt;確率的バンディット問題の設定とは&lt;/h2&gt;

&lt;p&gt;それぞれのアームを$i=1,\dots,K$とする．
対応する$[0,1]$上の未知の確率分布を$\nu_i$とする．
選択したアームに対応するが確率分布$\nu_i$には依存しない報酬を$X_{i,t}$とする．&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;確率的バンディット問題&lt;/em&gt;&lt;br /&gt;
既知のパラメータ：アーム数$K$，取りうるラウンド数$n\ge K$&lt;br /&gt;
未知のパラメータ：$[0,1]$上の$K$個の確率分布$\nu_1,\nu_2,\dots,\nu_K$&lt;br /&gt;
各ラウンドに対して，&lt;br /&gt;
1. 予測者はアーム$I_t\in\{1,\dots,K\}$を選ぶ
2. 与えられた選択$I_t$に対して，過去に依存しない報酬$X_{I_t,t}\sim\nu_{I_t}$が環境から支払われ，予測者に明らかになる．&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;$i=1,\dots,K$に対して，$\nu_i$の平均（アーム$i$の報酬の平均）を$\mu_i$と記す．
また，平均が最大のアームの平均値とそのアームのインデックスを$\mu^*=\max_{i=1,\dots,K}\mu_i$と$i^*=\rm arg\max_{i=1,\dots,K}\mu_i$とする．
擬リグレットは$$\overline{R}_n=n\mu^*-\sum_{t=1}^n\mathbb{E}[\mu_{I_t}]$$
とかける．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems １章 (1)</title>
      <link>https://getumen.github.io/2019/01/01/regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems-%EF%BC%91%E7%AB%A0-1/</link>
      <pubDate>Tue, 01 Jan 2019 00:01:00 +0900</pubDate>
      
      <guid>https://getumen.github.io/2019/01/01/regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems-%EF%BC%91%E7%AB%A0-1/</guid>
      <description>&lt;h1 id=&#34;導入&#34;&gt;導入&lt;/h1&gt;

&lt;h2 id=&#34;マルチアームバンディット問題とは&#34;&gt;マルチアームバンディット問題とは&lt;/h2&gt;

&lt;p&gt;マルチアームバンディット問題は行動の候補からそのラウンドに行う行動を繰り返し割り当てる問題である．
各ラウンドで，１つの行動を割り当て，報酬を受け取る．
このときのゴールは報酬の合計が最大になるように繰り返し行動を割り当てることである．
バンディットという名前はアメリカのスロットマシンのスラングに由来している．
カジノで，プレイヤーがたくさんのスロットマシンからアームを引くスロットマシンを次々に選んで，コインを入れていく問題がマルチアームバンディット問題となる．&lt;/p&gt;

&lt;p&gt;バンディット問題は限られた情報の中で繰り返し意思決定していく問題である．そして，この問題は繰り返しの試行の中で，過去にうまく行ったアームを引き続けるのか，今後より高い報酬を返すかもしれないアームを探すのかという探索と活用のトレードオフに直面する．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems</title>
      <link>https://getumen.github.io/2019/01/01/regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0900</pubDate>
      
      <guid>https://getumen.github.io/2019/01/01/regret-analysis-of-stochastic-and-nonstochastic-multi-armed-bandit-problems/</guid>
      <description>&lt;h1 id=&#34;このページについて&#34;&gt;このページについて&lt;/h1&gt;

&lt;p&gt;バンディット問題に対するアルゴリズムについてのサーベイ論文である&lt;a href=&#34;http://sbubeck.com/SurveyBCB12.pdf&#34;&gt;Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems&lt;/a&gt;を読んでまとめる．&lt;br /&gt;
このページでは概要の全訳と他の投稿のリンクを貼る．&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>